





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns





df = pd.read_csv('tested.csv')
orig_df = df
df.head()





df.dtypes


# !pip install ydata-profiling

# from ydata_profiling import ProfileReport
# profile = ProfileReport(df)

# profile


df.shape


df.describe()





print("Valores faltantes")
display(df.isnull().sum())
print("Percentual dos valores faltantes")
display(df.isnull().mean())


display(df.Sex.value_counts())
display(df.Embarked.value_counts())
display(df.Survived.value_counts())





df.head()
df = df.drop(columns = ['PassengerId','Name','Ticket','Cabin'])


df = pd.get_dummies(df, drop_first = True)
df.columns


y = df['Survived']
X = df.drop(columns = ['Survived'])


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)





from os import pipe
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

num_cols = ['Pclass','Age','SibSp','Parch','Fare','Sex_male','Embarked_Q','Embarked_S']

imputer = IterativeImputer(random_state = 42)

imputed = imputer.fit_transform(x_train[num_cols])
x_train[num_cols] = imputed
imputed = imputer.transform(x_test[num_cols])
x_test[num_cols] = imputed


# from sklearn.pipeline import Pipeline
# from sklearn.impute import SimpleImputer
# from sklearn.compose import ColumnTransformer

# numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
# categorical_features = ['Sex_male', 'Embarked_Q', 'Embarked_S']

# numeric_transformer = Pipeline(steps = [
#     ('imputer', SimpleImputer(strategy = 'median'))
# ])

# categorical_transformer = Pipeline(steps = [
#     ('imputer',SimpleImputer(strategy='most_frequent'))
# ])

# pre_processor = ColumnTransformer(
#     transformers = [
#         ('num', numeric_transformer, numeric_features),
#         ('cat', categorical_transformer, categorical_features)
#     ]
# )

# pipeline = Pipeline(steps=[('preprocessor', pre_processor)])

# x_train = pipeline.fit_transform(x_train)
# x_test = pipeline.transform(x_test)


x_train





from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()


x_train = scaler.fit_transform(x_train)
x_train = pd.DataFrame(x_train, columns = num_cols)
x_test = scaler.transform(x_test)
x_test = pd.DataFrame(x_test, columns = num_cols)


x_train





# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler
# from sklearn.experimental import enable_iterative_imputer
# from sklearn.impute import IterativeImputer

def tweak_titanic(df):
    df = df.drop(
        columns=[
            'PassengerId',
            'Name',
            'Ticket',
            'Cabin'
        ]
    ).pipe(pd.get_dummies, drop_first=True)
    return df

def get_train_test_X_y(df, y_col, size=0.3, std_cols=None):
    y = df[y_col]
    X = df.drop(columns=[y_col])  # Use drop with parentheses
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, random_state=42)
    
    num_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
    
    fi = IterativeImputer()
    X_train[num_cols] = fi.fit_transform(X_train[num_cols])
    X_test[num_cols] = fi.transform(X_test[num_cols])  # Use transform instead of fit_transform

    if std_cols:
        std = StandardScaler()
        X_train[std_cols] = std.fit_transform(X_train[std_cols])
        X_test[std_cols] = std.transform(X_test[std_cols])  # Use transform instead of fit_transform

    return X_train, X_test, y_train, y_test

# Preprocessing and splitting
ti_df = tweak_titanic(orig_df)
std_cols = ["Pclass", "Age", "SibSp", "Fare"]  # Ensure consistent naming
X_train, X_test, y_train, y_test = get_train_test_X_y(ti_df, "Survived", std_cols=std_cols)






from sklearn.dummy import DummyClassifier
bm = DummyClassifier()
bm.fit(X_train,y_train)
score = bm.score(X_test,y_test) # precisao

print(score)



